{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 16:02:38 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
      "0  1  Female  18.0             0              0           No        Private   \n",
      "1  2    Male  58.0             1              0          Yes        Private   \n",
      "2  3  Female  36.0             0              0          Yes       Govt_job   \n",
      "3  4  Female  62.0             0              0          Yes  Self-employed   \n",
      "4  5  Female  82.0             0              0          Yes        Private   \n",
      "\n",
      "  Residence_type  avg_glucose_level    bmi   smoking_status  stroke  \n",
      "0          Urban              94.19  12.12           smokes       1  \n",
      "1          Rural             154.24  33.70     never_smoked       0  \n",
      "2          Urban              72.63  24.70           smokes       0  \n",
      "3          Rural              85.52  31.20  formerly smoked       0  \n",
      "4          Rural              59.32  33.20           smokes       1  \n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.types import IntegerType, LongType, FloatType, DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StrokeDataAnalysis\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "df = pd.read_csv(\"./stroke_data.csv\")\n",
    "df_spark = spark.read.csv('./stroke_data.csv')\n",
    "\n",
    "print(df.head())\n",
    "df_spark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 16:02:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
      "0  1  Female  18.0             0              0           No        Private   \n",
      "1  2    Male  58.0             1              0          Yes        Private   \n",
      "2  3  Female  36.0             0              0          Yes       Govt_job   \n",
      "3  4  Female  62.0             0              0          Yes  Self-employed   \n",
      "4  5  Female  82.0             0              0          Yes        Private   \n",
      "\n",
      "  Residence_type  avg_glucose_level    bmi   smoking_status  stroke  \n",
      "0          Urban              94.19  12.12           smokes       1  \n",
      "1          Rural             154.24  33.70     never_smoked       0  \n",
      "2          Urban              72.63  24.70           smokes       0  \n",
      "3          Rural              85.52  31.20  formerly smoked       0  \n",
      "4          Rural              59.32  33.20           smokes       1  \n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Proporção de participantes por gênero\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"./stroke_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df = pd.read_csv(\"./stroke_data.csv\")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registro: 67135\n"
     ]
    }
   ],
   "source": [
    "#QUESTAO 1:\n",
    "\n",
    "num_registros = df.shape[0]\n",
    "print(f'Número de registro: {num_registros}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de colunas: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 16:02:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n",
      "Número de colunas numéricas: 7\n"
     ]
    }
   ],
   "source": [
    "#QUESTAO 2:\n",
    "\n",
    "total_colunas = len(df.columns)\n",
    "print(f'Número total de colunas: {total_colunas}')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Stroke Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "df = spark.read.csv('./stroke_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "numeric_types = (IntegerType, LongType, FloatType, DoubleType)\n",
    "num_numeric_columns = len([field for field in df.schema.fields if isinstance(field.dataType, numeric_types)])\n",
    "\n",
    "\n",
    "print(f'Número de colunas numéricas: {num_numeric_columns}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|40287|\n",
      "|     0|26848|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 3:\n",
    "\n",
    "stroke_counts = df.groupBy(\"stroke\").count()\n",
    "stroke_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|    work_type|stroke_count|\n",
      "+-------------+------------+\n",
      "| Never_worked|          85|\n",
      "|Self-employed|       10807|\n",
      "|      Private|       23711|\n",
      "|     children|         520|\n",
      "|     Govt_job|        5164|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTÃO 4:\n",
    "\n",
    "df.createOrReplaceTempView('stroke_table')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT work_type, COUNT(*) as stroke_count\n",
    "FROM stroke_table\n",
    "WHERE stroke = 1\n",
    "GROUP BY work_type\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "|gender|total_participantes|           proporcao|\n",
      "+------+-------------------+--------------------+\n",
      "|Female|              39530|  0.5888135845684069|\n",
      "| Other|                 11|1.638489610486333...|\n",
      "|  Male|              27594|  0.4110225664705444|\n",
      "+------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#QUESTÃO 5:\n",
    "\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_data\")\n",
    "consulta = \"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    COUNT(*) AS total_participantes,\n",
    "    COUNT(*) / (SELECT COUNT(*) FROM stroke_data) AS proporcao\n",
    "FROM \n",
    "    stroke_data\n",
    "GROUP BY \n",
    "    gender\n",
    "\"\"\"\n",
    "\n",
    "resultado = spark.sql(consulta)\n",
    "\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----------------------------------+\n",
      "|total_hipertensos_com_derrame|percentual_hipertensos_com_derrame|\n",
      "+-----------------------------+----------------------------------+\n",
      "|                         8817|                0.8003086139602432|\n",
      "+-----------------------------+----------------------------------+\n",
      "\n",
      "+---------------------------------+--------------------------------------+\n",
      "|total_nao_hipertensos_com_derrame|percentual_nao_hipertensos_com_derrame|\n",
      "+---------------------------------+--------------------------------------+\n",
      "|                            31470|                    0.5607826365871913|\n",
      "+---------------------------------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTÃO 6:\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_data\")\n",
    "\n",
    "consulta_hipertensos = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS total_hipertensos_com_derrame,\n",
    "    COUNT(*) / (SELECT COUNT(*) FROM stroke_data WHERE hypertension = 1) AS percentual_hipertensos_com_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    hypertension = 1\n",
    "    AND stroke = 1\n",
    "\"\"\"\n",
    "\n",
    "resultado_hipertensos = spark.sql(consulta_hipertensos)\n",
    "\n",
    "resultado_hipertensos.show()\n",
    "\n",
    "consulta_nao_hipertensos = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS total_nao_hipertensos_com_derrame,\n",
    "    COUNT(*) / (SELECT COUNT(*) FROM stroke_data WHERE hypertension = 0) AS percentual_nao_hipertensos_com_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    hypertension = 0\n",
    "    AND stroke = 1\n",
    "\"\"\"\n",
    "\n",
    "resultado_nao_hipertensos = spark.sql(consulta_nao_hipertensos)\n",
    "\n",
    "resultado_nao_hipertensos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------+\n",
      "| age|total_pessoas_com_derrame|\n",
      "+----+-------------------------+\n",
      "|79.0|                     2916|\n",
      "|78.0|                     2279|\n",
      "|80.0|                     1858|\n",
      "|81.0|                     1738|\n",
      "|82.0|                     1427|\n",
      "|77.0|                      994|\n",
      "|74.0|                      987|\n",
      "|63.0|                      942|\n",
      "|76.0|                      892|\n",
      "|70.0|                      881|\n",
      "|66.0|                      848|\n",
      "|75.0|                      809|\n",
      "|67.0|                      801|\n",
      "|57.0|                      775|\n",
      "|73.0|                      759|\n",
      "|65.0|                      716|\n",
      "|72.0|                      709|\n",
      "|68.0|                      688|\n",
      "|69.0|                      677|\n",
      "|71.0|                      667|\n",
      "+----+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "A idade com o maior número de pessoas que sofreram derrame é: 79.0\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 7:\n",
    "\n",
    "consulta = \"\"\"\n",
    "SELECT \n",
    "    age,\n",
    "    COUNT(*) AS total_pessoas_com_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    stroke = 1\n",
    "GROUP BY \n",
    "    age\n",
    "ORDER BY \n",
    "    total_pessoas_com_derrame DESC\n",
    "\"\"\"\n",
    "\n",
    "resultado = spark.sql(consulta)\n",
    "\n",
    "resultado.show()\n",
    "\n",
    "idade_maior_numero_derrames = resultado.select(\"age\").first()[0]\n",
    "print(f\"A idade com o maior número de pessoas que sofreram derrame é: {idade_maior_numero_derrames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pessoas que sofreram derrame após os 50 anos: 28938\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 8:\n",
    "pessoas_com_derrame_apos_50 = df.filter((col(\"age\") > 50) & (col(\"stroke\") == 1))\n",
    "\n",
    "total_pessoas_com_derrame_apos_50 = pessoas_com_derrame_apos_50.count()\n",
    "\n",
    "print(f\"Total de pessoas que sofreram derrame após os 50 anos: {total_pessoas_com_derrame_apos_50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nível médio de glicose para pessoas que sofreram derrame: 119.95\n",
      "Nível médio de glicose para pessoas que não sofreram derrame: 103.60\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 9:\n",
    "\n",
    "consulta_com_derrame = \"\"\"\n",
    "SELECT \n",
    "    AVG(avg_glucose_level) AS nivel_medio_glicose_com_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    stroke = 1\n",
    "\"\"\"\n",
    "\n",
    "resultado_com_derrame = spark.sql(consulta_com_derrame)\n",
    "\n",
    "nivel_medio_glicose_com_derrame = resultado_com_derrame.first()[0]\n",
    "print(f\"Nível médio de glicose para pessoas que sofreram derrame: {nivel_medio_glicose_com_derrame:.2f}\")\n",
    "\n",
    "consulta_sem_derrame = \"\"\"\n",
    "SELECT \n",
    "    AVG(avg_glucose_level) AS nivel_medio_glicose_sem_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    stroke = 0\n",
    "\"\"\"\n",
    "\n",
    "resultado_sem_derrame = spark.sql(consulta_sem_derrame)\n",
    "\n",
    "nivel_medio_glicose_sem_derrame = resultado_sem_derrame.first()[0]\n",
    "print(f\"Nível médio de glicose para pessoas que não sofreram derrame: {nivel_medio_glicose_sem_derrame:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI médio para pessoas que sofreram derrame: 29.94\n",
      "BMI médio para pessoas que não sofreram derrame: 27.99\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 10:\n",
    "\n",
    "consulta_com_derrame = \"\"\"\n",
    "SELECT \n",
    "    AVG(bmi) AS bmi_medio_com_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    stroke = 1\n",
    "\"\"\"\n",
    "\n",
    "resultado_com_derrame = spark.sql(consulta_com_derrame)\n",
    "\n",
    "bmi_medio_com_derrame = resultado_com_derrame.first()[0]\n",
    "print(f\"BMI médio para pessoas que sofreram derrame: {bmi_medio_com_derrame:.2f}\")\n",
    "\n",
    "consulta_sem_derrame = \"\"\"\n",
    "SELECT \n",
    "    AVG(bmi) AS bmi_medio_sem_derrame\n",
    "FROM \n",
    "    stroke_data\n",
    "WHERE \n",
    "    stroke = 0\n",
    "\"\"\"\n",
    "\n",
    "resultado_sem_derrame = spark.sql(consulta_sem_derrame)\n",
    "\n",
    "bmi_medio_sem_derrame = resultado_sem_derrame.first()[0]\n",
    "print(f\"BMI médio para pessoas que não sofreram derrame: {bmi_medio_sem_derrame:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 16:02:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.6483\n"
     ]
    }
   ],
   "source": [
    "# QUESTÃO 11:\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Modelo de Árvore de Decisão para Previsão de Stroke\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv('./stroke_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "data = df.select(\"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\", \"stroke\")\n",
    "\n",
    "feature_columns = [\"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"stroke\", featuresCol=\"features\", seed=1234)\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"stroke\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Acurácia do modelo: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.7947\n"
     ]
    }
   ],
   "source": [
    "# questao 12:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Modelo de Árvore de Decisão para Previsão de Stroke\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv('stroke_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "data = df.select(\"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\", \"gender\", \"smoking_status\", \"stroke\")\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"skip\") for column in [\"gender\", \"smoking_status\"]]\n",
    "encoder = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_encoded\") for column in [\"gender\", \"smoking_status\"]]\n",
    "assembler = VectorAssembler(inputCols=[\"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\", \"gender_encoded\", \"smoking_status_encoded\"], outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoder + [assembler])\n",
    "\n",
    "pipeline_model = pipeline.fit(data)\n",
    "transformed_data = pipeline_model.transform(data)\n",
    "\n",
    "train_data, test_data = transformed_data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"stroke\", featuresCol=\"features\", seed=1234)\n",
    "\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"stroke\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Acurácia do modelo: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variável mais importante no modelo é: age\n"
     ]
    }
   ],
   "source": [
    "# QUESTÃO 13:\n",
    "\n",
    "importances = {feature: feature_importances[i] for i, feature in enumerate(feature_columns)}\n",
    "most_important_feature = max(importances, key=importances.get)\n",
    "print(f\"A variável mais importante no modelo é: {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A profundidade da árvore de decisão é: 5\n"
     ]
    }
   ],
   "source": [
    "# questao 14:\n",
    "\n",
    "tree_depth = model.depth\n",
    "print(f\"A profundidade da árvore de decisão é: {tree_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de nodos na árvore de decisão é: 19\n"
     ]
    }
   ],
   "source": [
    "# QUESTAO 15:\n",
    "\n",
    "\n",
    "num_nodes = model.numNodes\n",
    "print(f\"O número de nodos na árvore de decisão é: {num_nodes}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
